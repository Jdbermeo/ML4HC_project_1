{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "certain-island",
   "metadata": {
    "id": "YZkwvMYrL990"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras_unet in c:\\users\\juan diego\\documents\\ondemna\\venv\\lib\\site-packages (0.1.2)\n",
      "Requirement already satisfied: nibabel in c:\\users\\juan diego\\documents\\ondemna\\venv\\lib\\site-packages (3.2.1)\n",
      "Requirement already satisfied: numpy>=1.14 in c:\\users\\juan diego\\documents\\ondemna\\venv\\lib\\site-packages (from nibabel) (1.19.5)\n",
      "Requirement already satisfied: packaging>=14.3 in c:\\users\\juan diego\\documents\\ondemna\\venv\\lib\\site-packages (from nibabel) (20.9)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\juan diego\\documents\\ondemna\\venv\\lib\\site-packages (from packaging>=14.3->nibabel) (2.4.7)\n",
      "Requirement already satisfied: focal-loss in c:\\users\\juan diego\\documents\\ondemna\\venv\\lib\\site-packages (0.0.6)\n",
      "Requirement already satisfied: tensorflow>=2.2 in c:\\users\\juan diego\\documents\\ondemna\\venv\\lib\\site-packages (from focal-loss) (2.4.1)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\juan diego\\documents\\ondemna\\venv\\lib\\site-packages (from tensorflow>=2.2->focal-loss) (3.15.6)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in c:\\users\\juan diego\\documents\\ondemna\\venv\\lib\\site-packages (from tensorflow>=2.2->focal-loss) (1.6.3)\n",
      "Requirement already satisfied: wheel~=0.35 in c:\\users\\juan diego\\documents\\ondemna\\venv\\lib\\site-packages (from tensorflow>=2.2->focal-loss) (0.36.2)\n",
      "Requirement already satisfied: tensorboard~=2.4 in c:\\users\\juan diego\\documents\\ondemna\\venv\\lib\\site-packages (from tensorflow>=2.2->focal-loss) (2.4.1)\n",
      "Requirement already satisfied: numpy~=1.19.2 in c:\\users\\juan diego\\documents\\ondemna\\venv\\lib\\site-packages (from tensorflow>=2.2->focal-loss) (1.19.5)\n",
      "Requirement already satisfied: gast==0.3.3 in c:\\users\\juan diego\\documents\\ondemna\\venv\\lib\\site-packages (from tensorflow>=2.2->focal-loss) (0.3.3)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in c:\\users\\juan diego\\documents\\ondemna\\venv\\lib\\site-packages (from tensorflow>=2.2->focal-loss) (1.12.1)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in c:\\users\\juan diego\\documents\\ondemna\\venv\\lib\\site-packages (from tensorflow>=2.2->focal-loss) (1.1.0)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in c:\\users\\juan diego\\documents\\ondemna\\venv\\lib\\site-packages (from tensorflow>=2.2->focal-loss) (3.7.4.3)\n",
      "Requirement already satisfied: grpcio~=1.32.0 in c:\\users\\juan diego\\documents\\ondemna\\venv\\lib\\site-packages (from tensorflow>=2.2->focal-loss) (1.32.0)\n",
      "Requirement already satisfied: h5py~=2.10.0 in c:\\users\\juan diego\\documents\\ondemna\\venv\\lib\\site-packages (from tensorflow>=2.2->focal-loss) (2.10.0)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in c:\\users\\juan diego\\documents\\ondemna\\venv\\lib\\site-packages (from tensorflow>=2.2->focal-loss) (1.1.2)\n",
      "Requirement already satisfied: absl-py~=0.10 in c:\\users\\juan diego\\documents\\ondemna\\venv\\lib\\site-packages (from tensorflow>=2.2->focal-loss) (0.12.0)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in c:\\users\\juan diego\\documents\\ondemna\\venv\\lib\\site-packages (from tensorflow>=2.2->focal-loss) (3.3.0)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in c:\\users\\juan diego\\documents\\ondemna\\venv\\lib\\site-packages (from tensorflow>=2.2->focal-loss) (1.12)\n",
      "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in c:\\users\\juan diego\\documents\\ondemna\\venv\\lib\\site-packages (from tensorflow>=2.2->focal-loss) (2.4.0)\n",
      "Requirement already satisfied: six~=1.15.0 in c:\\users\\juan diego\\documents\\ondemna\\venv\\lib\\site-packages (from tensorflow>=2.2->focal-loss) (1.15.0)\n",
      "Requirement already satisfied: google-pasta~=0.2 in c:\\users\\juan diego\\documents\\ondemna\\venv\\lib\\site-packages (from tensorflow>=2.2->focal-loss) (0.2.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\juan diego\\documents\\ondemna\\venv\\lib\\site-packages (from tensorboard~=2.4->tensorflow>=2.2->focal-loss) (52.0.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\juan diego\\documents\\ondemna\\venv\\lib\\site-packages (from tensorboard~=2.4->tensorflow>=2.2->focal-loss) (1.8.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\juan diego\\documents\\ondemna\\venv\\lib\\site-packages (from tensorboard~=2.4->tensorflow>=2.2->focal-loss) (2.25.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\juan diego\\documents\\ondemna\\venv\\lib\\site-packages (from tensorboard~=2.4->tensorflow>=2.2->focal-loss) (0.4.3)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\juan diego\\documents\\ondemna\\venv\\lib\\site-packages (from tensorboard~=2.4->tensorflow>=2.2->focal-loss) (1.0.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\juan diego\\documents\\ondemna\\venv\\lib\\site-packages (from tensorboard~=2.4->tensorflow>=2.2->focal-loss) (3.3.4)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in c:\\users\\juan diego\\documents\\ondemna\\venv\\lib\\site-packages (from tensorboard~=2.4->tensorflow>=2.2->focal-loss) (1.27.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\juan diego\\documents\\ondemna\\venv\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.2->focal-loss) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\juan diego\\documents\\ondemna\\venv\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.2->focal-loss) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\juan diego\\documents\\ondemna\\venv\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.2->focal-loss) (4.2.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\juan diego\\documents\\ondemna\\venv\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.2->focal-loss) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\juan diego\\documents\\ondemna\\venv\\lib\\site-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow>=2.2->focal-loss) (3.4.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\juan diego\\documents\\ondemna\\venv\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.2->focal-loss) (0.4.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\juan diego\\documents\\ondemna\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=2.2->focal-loss) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\juan diego\\documents\\ondemna\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=2.2->focal-loss) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\juan diego\\documents\\ondemna\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=2.2->focal-loss) (2020.12.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\juan diego\\documents\\ondemna\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=2.2->focal-loss) (1.26.3)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\juan diego\\documents\\ondemna\\venv\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.2->focal-loss) (3.1.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\juan diego\\documents\\ondemna\\venv\\lib\\site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.4->tensorflow>=2.2->focal-loss) (3.4.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras_unet\n",
    "!pip install nibabel\n",
    "!pip install focal-loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "organized-swaziland",
   "metadata": {
    "id": "reported-contest"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "keras-unet init: TF version is >= 2.0.0 - using `tf.keras` instead of `Keras`\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold \n",
    "from keras_unet.models import custom_unet\n",
    "import keras\n",
    "import tensorflow as tf \n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from keras_unet.metrics import iou, iou_thresholded, dice_coef\n",
    "#from google.colab import drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "amateur-september",
   "metadata": {
    "id": "oPwLLuomLyei"
   },
   "outputs": [],
   "source": [
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "hungry-excess",
   "metadata": {
    "id": "P7Yuu5nnL2BV"
   },
   "outputs": [],
   "source": [
    "#os.chdir('drive/My Drive/ML4HC Task1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "owned-mining",
   "metadata": {
    "id": "referenced-venezuela"
   },
   "outputs": [],
   "source": [
    "from img_generator import build_train_test_df, DataGenerator2D, DataGenerator3D\n",
    "from model_utils import calculate_iou_holdout_set, jaccard_distance_loss, focal_loss, dice_coef_loss, binary_focal_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "structural-piano",
   "metadata": {
    "id": "asian-maria"
   },
   "source": [
    "## Create dataframes in the format and with the information required by the generator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charming-first",
   "metadata": {
    "id": "incident-zimbabwe"
   },
   "source": [
    "### Create datframes with paths and depth for the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "authorized-coating",
   "metadata": {
    "id": "invalid-mills"
   },
   "outputs": [],
   "source": [
    "data_path_source_dir = os.path.join('ml4h_proj1_colon_cancer_ct', 'ml4h_proj1_colon_cancer_ct')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "wired-representation",
   "metadata": {
    "id": "subtle-borough"
   },
   "outputs": [],
   "source": [
    "tr_df, x_ts_df = build_train_test_df(data_path_source_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "annoying-virginia",
   "metadata": {
    "id": "Rx-ulGmMyHM6"
   },
   "outputs": [],
   "source": [
    "tr_3d_df = tr_df.reset_index(level=1).drop_duplicates(['x_tr_img_path', 'y_tr_img_path'], keep='last')\\\n",
    "                .loc[:, ['x_tr_img_path', 'y_tr_img_path', 'depth']]\n",
    "\n",
    "x_ts_3d_df = x_ts_df.reset_index(level=1).drop_duplicates(['x_ts_img_path'], keep='last')\\\n",
    "                .loc[:, ['x_ts_img_path', 'depth']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "continental-albania",
   "metadata": {
    "id": "_Zx3UvA9yjWd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_tr_img_path</th>\n",
       "      <th>y_tr_img_path</th>\n",
       "      <th>depth</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>001</th>\n",
       "      <td>ml4h_proj1_colon_cancer_ct\\ml4h_proj1_colon_ca...</td>\n",
       "      <td>ml4h_proj1_colon_cancer_ct\\ml4h_proj1_colon_ca...</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>005</th>\n",
       "      <td>ml4h_proj1_colon_cancer_ct\\ml4h_proj1_colon_ca...</td>\n",
       "      <td>ml4h_proj1_colon_cancer_ct\\ml4h_proj1_colon_ca...</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>006</th>\n",
       "      <td>ml4h_proj1_colon_cancer_ct\\ml4h_proj1_colon_ca...</td>\n",
       "      <td>ml4h_proj1_colon_cancer_ct\\ml4h_proj1_colon_ca...</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>007</th>\n",
       "      <td>ml4h_proj1_colon_cancer_ct\\ml4h_proj1_colon_ca...</td>\n",
       "      <td>ml4h_proj1_colon_cancer_ct\\ml4h_proj1_colon_ca...</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           x_tr_img_path  \\\n",
       "index                                                      \n",
       "001    ml4h_proj1_colon_cancer_ct\\ml4h_proj1_colon_ca...   \n",
       "005    ml4h_proj1_colon_cancer_ct\\ml4h_proj1_colon_ca...   \n",
       "006    ml4h_proj1_colon_cancer_ct\\ml4h_proj1_colon_ca...   \n",
       "007    ml4h_proj1_colon_cancer_ct\\ml4h_proj1_colon_ca...   \n",
       "\n",
       "                                           y_tr_img_path  depth  \n",
       "index                                                            \n",
       "001    ml4h_proj1_colon_cancer_ct\\ml4h_proj1_colon_ca...     60  \n",
       "005    ml4h_proj1_colon_cancer_ct\\ml4h_proj1_colon_ca...     98  \n",
       "006    ml4h_proj1_colon_cancer_ct\\ml4h_proj1_colon_ca...     68  \n",
       "007    ml4h_proj1_colon_cancer_ct\\ml4h_proj1_colon_ca...     74  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_3d_df.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parental-finnish",
   "metadata": {
    "id": "C5iYQhB6yH4H"
   },
   "source": [
    "As we are going to read 3d image by 3d image, let's modify the dataframes so that they are not indexed by the number of cuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "popular-syria",
   "metadata": {
    "id": "internal-headquarters"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_ts_img_path</th>\n",
       "      <th>depth</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>ml4h_proj1_colon_cancer_ct\\ml4h_proj1_colon_ca...</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>ml4h_proj1_colon_cancer_ct\\ml4h_proj1_colon_ca...</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>ml4h_proj1_colon_cancer_ct\\ml4h_proj1_colon_ca...</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>ml4h_proj1_colon_cancer_ct\\ml4h_proj1_colon_ca...</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           x_ts_img_path  depth\n",
       "index                                                          \n",
       "171    ml4h_proj1_colon_cancer_ct\\ml4h_proj1_colon_ca...    119\n",
       "172    ml4h_proj1_colon_cancer_ct\\ml4h_proj1_colon_ca...     81\n",
       "175    ml4h_proj1_colon_cancer_ct\\ml4h_proj1_colon_ca...     90\n",
       "176    ml4h_proj1_colon_cancer_ct\\ml4h_proj1_colon_ca...    113"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_ts_3d_df.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "possible-evolution",
   "metadata": {
    "id": "published-witness"
   },
   "source": [
    "### Create CV folds for `tr_df`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "provincial-architecture",
   "metadata": {
    "id": "loose-startup"
   },
   "source": [
    "let's go for 10 folds to have a 90/10 split. We can still only use only 3 or 5 to estimate the metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dimensional-acquisition",
   "metadata": {
    "id": "cross-thickness"
   },
   "outputs": [],
   "source": [
    "def generate_fold_dict(df_, n_folds=3, seed=123):\n",
    "    \n",
    "    img_num_idx_list = df_.index\n",
    "    folder = KFold(n_splits=n_folds, random_state=seed, shuffle=True)\n",
    "    df_fold_dict = dict()\n",
    "    \n",
    "    for i, (train_fold_i, holdout_i) in enumerate(folder.split(img_num_idx_list)):\n",
    "        train_fold_i_idx = img_num_idx_list[train_fold_i]\n",
    "        holdout_i_idx = img_num_idx_list[holdout_i]\n",
    "\n",
    "        df_fold_dict[f'fold_{i}'] = {\n",
    "            'train': df_.loc[train_fold_i_idx, :],\n",
    "            'holdout': df_.loc[holdout_i_idx, :]\n",
    "        }\n",
    "        \n",
    "    return df_fold_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "italic-determination",
   "metadata": {
    "id": "political-print"
   },
   "outputs": [],
   "source": [
    "tr_fold_df_dict =  generate_fold_dict(df_=tr_3d_df, n_folds=10, seed=123) # 10 folds to have 90/10 split, but we can use only 3 or 5 to estimate the metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "mounted-strike",
   "metadata": {
    "id": "interracial-ontario"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_tr_img_path</th>\n",
       "      <th>y_tr_img_path</th>\n",
       "      <th>depth</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>005</th>\n",
       "      <td>ml4h_proj1_colon_cancer_ct\\ml4h_proj1_colon_ca...</td>\n",
       "      <td>ml4h_proj1_colon_cancer_ct\\ml4h_proj1_colon_ca...</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>006</th>\n",
       "      <td>ml4h_proj1_colon_cancer_ct\\ml4h_proj1_colon_ca...</td>\n",
       "      <td>ml4h_proj1_colon_cancer_ct\\ml4h_proj1_colon_ca...</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>007</th>\n",
       "      <td>ml4h_proj1_colon_cancer_ct\\ml4h_proj1_colon_ca...</td>\n",
       "      <td>ml4h_proj1_colon_cancer_ct\\ml4h_proj1_colon_ca...</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>011</th>\n",
       "      <td>ml4h_proj1_colon_cancer_ct\\ml4h_proj1_colon_ca...</td>\n",
       "      <td>ml4h_proj1_colon_cancer_ct\\ml4h_proj1_colon_ca...</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>012</th>\n",
       "      <td>ml4h_proj1_colon_cancer_ct\\ml4h_proj1_colon_ca...</td>\n",
       "      <td>ml4h_proj1_colon_cancer_ct\\ml4h_proj1_colon_ca...</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>ml4h_proj1_colon_cancer_ct\\ml4h_proj1_colon_ca...</td>\n",
       "      <td>ml4h_proj1_colon_cancer_ct\\ml4h_proj1_colon_ca...</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>ml4h_proj1_colon_cancer_ct\\ml4h_proj1_colon_ca...</td>\n",
       "      <td>ml4h_proj1_colon_cancer_ct\\ml4h_proj1_colon_ca...</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>ml4h_proj1_colon_cancer_ct\\ml4h_proj1_colon_ca...</td>\n",
       "      <td>ml4h_proj1_colon_cancer_ct\\ml4h_proj1_colon_ca...</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>ml4h_proj1_colon_cancer_ct\\ml4h_proj1_colon_ca...</td>\n",
       "      <td>ml4h_proj1_colon_cancer_ct\\ml4h_proj1_colon_ca...</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>ml4h_proj1_colon_cancer_ct\\ml4h_proj1_colon_ca...</td>\n",
       "      <td>ml4h_proj1_colon_cancer_ct\\ml4h_proj1_colon_ca...</td>\n",
       "      <td>258</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           x_tr_img_path  \\\n",
       "index                                                      \n",
       "005    ml4h_proj1_colon_cancer_ct\\ml4h_proj1_colon_ca...   \n",
       "006    ml4h_proj1_colon_cancer_ct\\ml4h_proj1_colon_ca...   \n",
       "007    ml4h_proj1_colon_cancer_ct\\ml4h_proj1_colon_ca...   \n",
       "011    ml4h_proj1_colon_cancer_ct\\ml4h_proj1_colon_ca...   \n",
       "012    ml4h_proj1_colon_cancer_ct\\ml4h_proj1_colon_ca...   \n",
       "...                                                  ...   \n",
       "164    ml4h_proj1_colon_cancer_ct\\ml4h_proj1_colon_ca...   \n",
       "165    ml4h_proj1_colon_cancer_ct\\ml4h_proj1_colon_ca...   \n",
       "166    ml4h_proj1_colon_cancer_ct\\ml4h_proj1_colon_ca...   \n",
       "168    ml4h_proj1_colon_cancer_ct\\ml4h_proj1_colon_ca...   \n",
       "169    ml4h_proj1_colon_cancer_ct\\ml4h_proj1_colon_ca...   \n",
       "\n",
       "                                           y_tr_img_path  depth  \n",
       "index                                                            \n",
       "005    ml4h_proj1_colon_cancer_ct\\ml4h_proj1_colon_ca...     98  \n",
       "006    ml4h_proj1_colon_cancer_ct\\ml4h_proj1_colon_ca...     68  \n",
       "007    ml4h_proj1_colon_cancer_ct\\ml4h_proj1_colon_ca...     74  \n",
       "011    ml4h_proj1_colon_cancer_ct\\ml4h_proj1_colon_ca...     90  \n",
       "012    ml4h_proj1_colon_cancer_ct\\ml4h_proj1_colon_ca...     88  \n",
       "...                                                  ...    ...  \n",
       "164    ml4h_proj1_colon_cancer_ct\\ml4h_proj1_colon_ca...     90  \n",
       "165    ml4h_proj1_colon_cancer_ct\\ml4h_proj1_colon_ca...    142  \n",
       "166    ml4h_proj1_colon_cancer_ct\\ml4h_proj1_colon_ca...     87  \n",
       "168    ml4h_proj1_colon_cancer_ct\\ml4h_proj1_colon_ca...     80  \n",
       "169    ml4h_proj1_colon_cancer_ct\\ml4h_proj1_colon_ca...    258  \n",
       "\n",
       "[90 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_fold_df_dict['fold_0']['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "super-fetish",
   "metadata": {
    "id": "front-transcript"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_tr_img_path</th>\n",
       "      <th>y_tr_img_path</th>\n",
       "      <th>depth</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>001</th>\n",
       "      <td>ml4h_proj1_colon_cancer_ct\\ml4h_proj1_colon_ca...</td>\n",
       "      <td>ml4h_proj1_colon_cancer_ct\\ml4h_proj1_colon_ca...</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>008</th>\n",
       "      <td>ml4h_proj1_colon_cancer_ct\\ml4h_proj1_colon_ca...</td>\n",
       "      <td>ml4h_proj1_colon_cancer_ct\\ml4h_proj1_colon_ca...</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>009</th>\n",
       "      <td>ml4h_proj1_colon_cancer_ct\\ml4h_proj1_colon_ca...</td>\n",
       "      <td>ml4h_proj1_colon_cancer_ct\\ml4h_proj1_colon_ca...</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>015</th>\n",
       "      <td>ml4h_proj1_colon_cancer_ct\\ml4h_proj1_colon_ca...</td>\n",
       "      <td>ml4h_proj1_colon_cancer_ct\\ml4h_proj1_colon_ca...</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>050</th>\n",
       "      <td>ml4h_proj1_colon_cancer_ct\\ml4h_proj1_colon_ca...</td>\n",
       "      <td>ml4h_proj1_colon_cancer_ct\\ml4h_proj1_colon_ca...</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>096</th>\n",
       "      <td>ml4h_proj1_colon_cancer_ct\\ml4h_proj1_colon_ca...</td>\n",
       "      <td>ml4h_proj1_colon_cancer_ct\\ml4h_proj1_colon_ca...</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>ml4h_proj1_colon_cancer_ct\\ml4h_proj1_colon_ca...</td>\n",
       "      <td>ml4h_proj1_colon_cancer_ct\\ml4h_proj1_colon_ca...</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>ml4h_proj1_colon_cancer_ct\\ml4h_proj1_colon_ca...</td>\n",
       "      <td>ml4h_proj1_colon_cancer_ct\\ml4h_proj1_colon_ca...</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>ml4h_proj1_colon_cancer_ct\\ml4h_proj1_colon_ca...</td>\n",
       "      <td>ml4h_proj1_colon_cancer_ct\\ml4h_proj1_colon_ca...</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>ml4h_proj1_colon_cancer_ct\\ml4h_proj1_colon_ca...</td>\n",
       "      <td>ml4h_proj1_colon_cancer_ct\\ml4h_proj1_colon_ca...</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           x_tr_img_path  \\\n",
       "index                                                      \n",
       "001    ml4h_proj1_colon_cancer_ct\\ml4h_proj1_colon_ca...   \n",
       "008    ml4h_proj1_colon_cancer_ct\\ml4h_proj1_colon_ca...   \n",
       "009    ml4h_proj1_colon_cancer_ct\\ml4h_proj1_colon_ca...   \n",
       "015    ml4h_proj1_colon_cancer_ct\\ml4h_proj1_colon_ca...   \n",
       "050    ml4h_proj1_colon_cancer_ct\\ml4h_proj1_colon_ca...   \n",
       "096    ml4h_proj1_colon_cancer_ct\\ml4h_proj1_colon_ca...   \n",
       "115    ml4h_proj1_colon_cancer_ct\\ml4h_proj1_colon_ca...   \n",
       "126    ml4h_proj1_colon_cancer_ct\\ml4h_proj1_colon_ca...   \n",
       "141    ml4h_proj1_colon_cancer_ct\\ml4h_proj1_colon_ca...   \n",
       "142    ml4h_proj1_colon_cancer_ct\\ml4h_proj1_colon_ca...   \n",
       "\n",
       "                                           y_tr_img_path  depth  \n",
       "index                                                            \n",
       "001    ml4h_proj1_colon_cancer_ct\\ml4h_proj1_colon_ca...     60  \n",
       "008    ml4h_proj1_colon_cancer_ct\\ml4h_proj1_colon_ca...    149  \n",
       "009    ml4h_proj1_colon_cancer_ct\\ml4h_proj1_colon_ca...     90  \n",
       "015    ml4h_proj1_colon_cancer_ct\\ml4h_proj1_colon_ca...     54  \n",
       "050    ml4h_proj1_colon_cancer_ct\\ml4h_proj1_colon_ca...    142  \n",
       "096    ml4h_proj1_colon_cancer_ct\\ml4h_proj1_colon_ca...     91  \n",
       "115    ml4h_proj1_colon_cancer_ct\\ml4h_proj1_colon_ca...     97  \n",
       "126    ml4h_proj1_colon_cancer_ct\\ml4h_proj1_colon_ca...     85  \n",
       "141    ml4h_proj1_colon_cancer_ct\\ml4h_proj1_colon_ca...     90  \n",
       "142    ml4h_proj1_colon_cancer_ct\\ml4h_proj1_colon_ca...    102  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_fold_df_dict['fold_0']['holdout']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decreased-devon",
   "metadata": {
    "id": "enormous-leave"
   },
   "source": [
    "## Let's create a generator for the trainset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corrected-rubber",
   "metadata": {
    "id": "combined-league"
   },
   "source": [
    "For the first fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "global-modern",
   "metadata": {
    "id": "R1WgzFGllkJw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "tr_fold_0_df = tr_fold_df_dict['fold_0']['train']\n",
    "holdout_fold_0_df = tr_fold_df_dict['fold_0']['holdout']\n",
    "resize_dim = (128, 128)\n",
    "print(tr_fold_0_df.shape[0])\n",
    "print(holdout_fold_0_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "growing-ancient",
   "metadata": {
    "id": "photographic-landing"
   },
   "outputs": [],
   "source": [
    "train_data_generator = DataGenerator3D(\n",
    "    df=tr_fold_0_df, x_col='x_tr_img_path', y_col='y_tr_img_path',\n",
    "    batch_size=1, shuffle=False, resize_dim=resize_dim, \n",
    "    hounsfield_min= -1000., hounsfield_max=400.,\n",
    "    rotate_range=30, horizontal_flip=True, vertical_flip=True,\n",
    "    random_crop=(0.8, 0.9)) #,\n",
    "    #shearing=((0.1, 0.3), (0., 0.0)), gaussian_blur=(0.3162, 0.9487))\n",
    "\n",
    "holdout_data_generator = DataGenerator3D(\n",
    "    df=holdout_fold_0_df, x_col='x_tr_img_path', y_col='y_tr_img_path',\n",
    "    batch_size=1, shuffle=False, resize_dim=resize_dim,\n",
    "    hounsfield_min= -1000., hounsfield_max=400.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "inner-convert",
   "metadata": {
    "id": "XqdZpW-slua2"
   },
   "outputs": [],
   "source": [
    "num_epoch = 5\n",
    "version = 1\n",
    "split = '90_10_split'\n",
    "loss_used = 'dice_loss'\n",
    "augmentations = 'flips_rot_crop'\n",
    "depth_shuffle = 'depth_shuffle'\n",
    "imbalance_sampling = '  '\n",
    "attepmt_name_dir = f'v{version}_{num_epoch}epochs_{split}_{loss_used}_{augmentations}_{depth_shuffle}_{imbalance_sampling}' \n",
    "attepmt_name_dir = os.path.join('training_runs', 'juan', '3dUnet', attepmt_name_dir)\n",
    "os.makedirs(attepmt_name_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "optimum-rwanda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Conv3D, Input, MaxPooling3D, Dropout, concatenate, UpSampling3D\n",
    "import tensorflow as tf\n",
    "\n",
    "def Unet3D(inputs, num_classes):\n",
    "    x=inputs\n",
    "    conv1 = Conv3D(8, 3, activation = 'relu', padding = 'same',data_format=\"channels_last\")(x)\n",
    "    conv1 = Conv3D(8, 3, activation = 'relu', padding = 'same')(conv1)\n",
    "    pool1 = MaxPooling3D(pool_size=(2, 2, 2))(conv1)\n",
    "    conv2 = Conv3D(16, 3, activation = 'relu', padding = 'same')(pool1)\n",
    "    conv2 = Conv3D(16, 3, activation = 'relu', padding = 'same')(conv2)\n",
    "    pool2 = MaxPooling3D(pool_size=(2, 2, 2))(conv2)\n",
    "    conv3 = Conv3D(32, 3, activation = 'relu', padding = 'same')(pool2)\n",
    "    conv3 = Conv3D(32, 3, activation = 'relu', padding = 'same')(conv3)\n",
    "    pool3 = MaxPooling3D(pool_size=(2, 2, 2))(conv3)\n",
    "    conv4 = Conv3D(64, 3, activation = 'relu', padding = 'same')(pool3)\n",
    "    conv4 = Conv3D(64, 3, activation = 'relu', padding = 'same')(conv4)\n",
    "    drop4 = Dropout(0.5)(conv4)\n",
    "    pool4 = MaxPooling3D(pool_size=(2, 2, 2))(drop4)\n",
    "\n",
    "    conv5 = Conv3D(128, 3, activation = 'relu', padding = 'same')(pool4)\n",
    "    conv5 = Conv3D(128, 3, activation = 'relu', padding = 'same')(conv5)\n",
    "    drop5 = Dropout(0.5)(conv5)\n",
    "\n",
    "    up6 = Conv3D(64, 2, activation = 'relu', padding = 'same')(UpSampling3D(size = (2,2,2))(drop5))\n",
    "    merge6 = concatenate([drop4,up6],axis=-1)\n",
    "    conv6 = Conv3D(64, 3, activation = 'relu', padding = 'same')(merge6)\n",
    "    conv6 = Conv3D(64, 3, activation = 'relu', padding = 'same')(conv6)\n",
    "\n",
    "    up7 = Conv3D(32, 2, activation = 'relu', padding = 'same')(UpSampling3D(size = (2,2,2))(conv6))\n",
    "    merge7 = concatenate([conv3,up7],axis=-1)\n",
    "    conv7 = Conv3D(32, 3, activation = 'relu', padding = 'same')(merge7)\n",
    "    conv7 = Conv3D(32, 3, activation = 'relu', padding = 'same')(conv7)\n",
    "\n",
    "    up8 = Conv3D(16, 2, activation = 'relu', padding = 'same')(UpSampling3D(size = (2,2,2))(conv7))\n",
    "    merge8 = concatenate([conv2,up8],axis=-1)\n",
    "    conv8 = Conv3D(16, 3, activation = 'relu', padding = 'same')(merge8)\n",
    "    conv8 = Conv3D(16, 3, activation = 'relu', padding = 'same')(conv8)\n",
    "\n",
    "    up9 = Conv3D(8, 2, activation = 'relu', padding = 'same')(UpSampling3D(size = (2,2,2))(conv8))\n",
    "    merge9 = concatenate([conv1,up9],axis=-1)\n",
    "    conv9 = Conv3D(8, 3, activation = 'relu', padding = 'same')(merge9)\n",
    "    conv9 = Conv3D(8, 3, activation = 'relu', padding = 'same')(conv9)\n",
    "    conv10 = Conv3D(1, 1, activation = 'sigmoid')(conv9)\n",
    "    model = Model(inputs=inputs, outputs = conv10)\n",
    "    #model.compile(optimizer = Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "military-andorra",
   "metadata": {
    "id": "dCpoainy2HpL"
   },
   "outputs": [],
   "source": [
    "def unet3d(n_levels, initial_features=32, n_blocks=2, kernel_size=3, pooling_size=2, strides=(1, 1, 2),\n",
    "         image_height=256, image_width=256, image_depth=None, in_channels=1, out_channels=1):\n",
    "    \n",
    "    inputs = keras.layers.Input(shape=(image_height, image_width, image_depth, in_channels))\n",
    "    x = inputs\n",
    "    \n",
    "    convpars = dict(kernel_size=kernel_size, activation='relu', padding='same')\n",
    "    \n",
    "    #downstream\n",
    "    skips = {}\n",
    "    for level in range(n_levels):\n",
    "        for _ in range(n_blocks):\n",
    "            x = keras.layers.Conv3D(initial_features * 2 ** level, **convpars)(x)\n",
    "        if level < n_levels - 1:\n",
    "            skips[level] = x\n",
    "            x = keras.layers.MaxPool3D(pooling_size)(x)\n",
    "            \n",
    "    # upstream\n",
    "    for level in reversed(range(n_levels-1)):\n",
    "        x = keras.layers.Conv3DTranspose(initial_features * 2 ** level, strides=pooling_size, **convpars)(x)\n",
    "        x = keras.layers.Concatenate()([x, skips[level]])\n",
    "        for _ in range(n_blocks):\n",
    "            x = keras.layers.Conv3D(initial_features * 2 ** level, **convpars)(x)\n",
    "            \n",
    "    # output\n",
    "    activation = 'sigmoid' if out_channels == 1 else 'softmax'\n",
    "    x = keras.layers.Conv3D(out_channels, kernel_size=1, activation=activation, padding='same')(x)\n",
    "    \n",
    "    return keras.Model(inputs=[inputs], outputs=[x], name=f'UNET-L{n_levels}-F{initial_features}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "manufactured-magic",
   "metadata": {
    "id": "promising-pride"
   },
   "outputs": [],
   "source": [
    "model_3D = unet3d(n_levels=4, initial_features=32, n_blocks=2, kernel_size=(3,3,3), pooling_size=2, strides=1,\n",
    "                image_height=128, image_width=128, image_depth=None, in_channels=1, out_channels=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "affiliated-favorite",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3D = Unet3D(inputs=keras.layers.Input(shape=(128, 128, None, 1)),\n",
    "                  num_classes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "progressive-gibson",
   "metadata": {
    "collapsed": true,
    "id": "4dWphhAIUAPz",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 128, 128, No 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_15 (Conv3D)              (None, 128, 128, Non 224         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_16 (Conv3D)              (None, 128, 128, Non 1736        conv3d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3D)  (None, 64, 64, None, 0           conv3d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_17 (Conv3D)              (None, 64, 64, None, 3472        max_pooling3d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_18 (Conv3D)              (None, 64, 64, None, 6928        conv3d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_4 (MaxPooling3D)  (None, 32, 32, None, 0           conv3d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_19 (Conv3D)              (None, 32, 32, None, 13856       max_pooling3d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_20 (Conv3D)              (None, 32, 32, None, 27680       conv3d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_5 (MaxPooling3D)  (None, 16, 16, None, 0           conv3d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_21 (Conv3D)              (None, 16, 16, None, 55360       max_pooling3d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_22 (Conv3D)              (None, 16, 16, None, 110656      conv3d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 16, 16, None, 0           conv3d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_6 (MaxPooling3D)  (None, 8, 8, None, 6 0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_23 (Conv3D)              (None, 8, 8, None, 1 221312      max_pooling3d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_24 (Conv3D)              (None, 8, 8, None, 1 442496      conv3d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 8, 8, None, 1 0           conv3d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling3d (UpSampling3D)    (None, 16, 16, None, 0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_25 (Conv3D)              (None, 16, 16, None, 65600       up_sampling3d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 16, 16, None, 0           dropout[0][0]                    \n",
      "                                                                 conv3d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_26 (Conv3D)              (None, 16, 16, None, 221248      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_27 (Conv3D)              (None, 16, 16, None, 110656      conv3d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling3d_1 (UpSampling3D)  (None, 32, 32, None, 0           conv3d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_28 (Conv3D)              (None, 32, 32, None, 16416       up_sampling3d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 32, 32, None, 0           conv3d_20[0][0]                  \n",
      "                                                                 conv3d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_29 (Conv3D)              (None, 32, 32, None, 55328       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_30 (Conv3D)              (None, 32, 32, None, 27680       conv3d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling3d_2 (UpSampling3D)  (None, 64, 64, None, 0           conv3d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_31 (Conv3D)              (None, 64, 64, None, 4112        up_sampling3d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 64, 64, None, 0           conv3d_18[0][0]                  \n",
      "                                                                 conv3d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_32 (Conv3D)              (None, 64, 64, None, 13840       concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_33 (Conv3D)              (None, 64, 64, None, 6928        conv3d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling3d_3 (UpSampling3D)  (None, 128, 128, Non 0           conv3d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_34 (Conv3D)              (None, 128, 128, Non 1032        up_sampling3d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 128, 128, Non 0           conv3d_16[0][0]                  \n",
      "                                                                 conv3d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_35 (Conv3D)              (None, 128, 128, Non 3464        concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_36 (Conv3D)              (None, 128, 128, Non 1736        conv3d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_37 (Conv3D)              (None, 128, 128, Non 9           conv3d_36[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,411,769\n",
      "Trainable params: 1,411,769\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_3D.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "periodic-medicare",
   "metadata": {
    "id": "pzyyPP_z0ICW"
   },
   "outputs": [],
   "source": [
    "my_callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(patience=20),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.1, patience=5, verbose=1),\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=os.path.join(f'{attepmt_name_dir}', 'model_sampling.{epoch:02d}-{val_loss:.2f}.h5')),\n",
    "    #tf.keras.callbacks.TensorBoard(log_dir=os.path.join(f'{attepmt_name_dir}', 'logs_new')),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "diverse-association",
   "metadata": {
    "id": "relative-baking"
   },
   "outputs": [],
   "source": [
    "model_3D.compile(\n",
    "    optimizer=Adam(learning_rate=0.001), \n",
    "    #optimizer=SGD(lr=0.01, momentum=0.99),\n",
    "    #loss='binary_crossentropy',\n",
    "    loss=dice_coef_loss,\n",
    "    metrics=[iou, iou_thresholded]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "graphic-taiwan",
   "metadata": {
    "id": "photographic-landing"
   },
   "outputs": [],
   "source": [
    "train_data_generator_1 = DataGenerator3D(\n",
    "    df=tr_fold_0_df.loc['005':'005'], x_col='x_tr_img_path', y_col='y_tr_img_path',\n",
    "    batch_size=1, shuffle=False, resize_dim=(128, 128, 128), \n",
    "    hounsfield_min= -1000., hounsfield_max=400.,\n",
    "    rotate_range=30, horizontal_flip=True, vertical_flip=True,\n",
    "    random_crop=(0.8, 0.9)) #,\n",
    "    #shearing=((0.1, 0.3), (0., 0.0)), gaussian_blur=(0.3162, 0.9487))\n",
    "\n",
    "train_data_generator_2 = DataGenerator3D(\n",
    "    df=tr_fold_0_df.loc['166':'166'], x_col='x_tr_img_path', y_col='y_tr_img_path',\n",
    "    batch_size=1, shuffle=False, resize_dim=resize_dim, \n",
    "    hounsfield_min= -1000., hounsfield_max=400.,\n",
    "    rotate_range=30, horizontal_flip=True, vertical_flip=True,\n",
    "    random_crop=(0.8, 0.9)) #,\n",
    "    #shearing=((0.1, 0.3), (0., 0.0)), gaussian_blur=(0.3162, 0.9487))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "brazilian-complaint",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "function takes exactly 2 arguments (3 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-74-ee82a31b0562>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data_generator_1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32massert\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\juan diego\\documents\\ondemna\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\data_utils.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    481\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    482\u001b[0m     \u001b[1;34m\"\"\"Create a generator that iterate over the Sequence.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 483\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    484\u001b[0m       \u001b[1;32myield\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    485\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\juan diego\\documents\\ondemna\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\data_utils.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    481\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    482\u001b[0m     \u001b[1;34m\"\"\"Create a generator that iterate over the Sequence.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 483\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    484\u001b[0m       \u001b[1;32myield\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    485\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\ML4HC\\Project_1\\img_generator.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    449\u001b[0m         \u001b[0mbatch_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 451\u001b[1;33m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_idx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    452\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    453\u001b[0m         \u001b[1;31m# If the depth is odd, pad it with zeroes to make it even\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\ML4HC\\Project_1\\img_generator.py\u001b[0m in \u001b[0;36m__get_data\u001b[1;34m(self, batch_idx)\u001b[0m\n\u001b[0;32m    489\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    490\u001b[0m             \u001b[1;31m# Preprocess image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 491\u001b[1;33m             \u001b[0mx_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocess_img\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_img\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    492\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    493\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my_col\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\ML4HC\\Project_1\\img_generator.py\u001b[0m in \u001b[0;36mpreprocess_img\u001b[1;34m(self, img_, label)\u001b[0m\n\u001b[0;32m    554\u001b[0m         \u001b[1;31m# Return them normalized\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    555\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize_dim\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 556\u001b[1;33m             \u001b[0mimg_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mINTER_AREA\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    557\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    558\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mimg_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: function takes exactly 2 arguments (3 given)"
     ]
    }
   ],
   "source": [
    "for i, (X, y) in enumerate(train_data_generator_1):\n",
    "    print(X.shape)\n",
    "    print(y.shape)\n",
    "    assert X.shape == y.shape\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "chronic-bankruptcy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 128, 128, 87, 1)\n",
      "(1, 128, 128, 87, 1)\n"
     ]
    }
   ],
   "source": [
    "for i, (X, y) in enumerate(train_data_generator_2):\n",
    "    print(X.shape)\n",
    "    print(y.shape)\n",
    "    assert X.shape == y.shape\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "facial-reform",
   "metadata": {
    "id": "promising-pride"
   },
   "outputs": [],
   "source": [
    "model_3D = unet3d(n_levels=4, initial_features=32, n_blocks=2, kernel_size=(3,3,3), pooling_size=2, strides=1,\n",
    "                image_height=128, image_width=128, image_depth=None, in_channels=1, out_channels=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "auburn-seminar",
   "metadata": {
    "id": "relative-baking"
   },
   "outputs": [],
   "source": [
    "model_3D.compile(\n",
    "    optimizer=Adam(learning_rate=0.001), \n",
    "    #optimizer=SGD(lr=0.01, momentum=0.99),\n",
    "    #loss='binary_crossentropy',\n",
    "    loss=dice_coef_loss,\n",
    "    metrics=[iou, iou_thresholded]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intensive-extension",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "smart-retreat",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 182
    },
    "executionInfo": {
     "elapsed": 492,
     "status": "error",
     "timestamp": 1616314670342,
     "user": {
      "displayName": "Juan Diego Bermeo",
      "photoUrl": "",
      "userId": "11124578296137739363"
     },
     "user_tz": -60
    },
    "id": "sharing-plaintiff",
    "outputId": "64966d74-296a-479e-9124-b3b14ed9ac5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": " ConcatOp : Dimensions of inputs should match: shape[0] = [1,64,64,48,64] vs. shape[1] = [1,64,64,49,64]\n\t [[node UNET-L4-F32/concatenate_14/concat (defined at <ipython-input-61-1f9e2dbe7e85>:2) ]] [Op:__inference_train_function_14285]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-61-1f9e2dbe7e85>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m model_3D.fit(train_data_generator_1, validation_data=holdout_data_generator,\n\u001b[1;32m----> 2\u001b[1;33m              epochs=num_epoch, callbacks=my_callbacks)\n\u001b[0m",
      "\u001b[1;32mc:\\users\\juan diego\\documents\\ondemna\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1098\u001b[0m                 _r=1):\n\u001b[0;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1101\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\juan diego\\documents\\ondemna\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\juan diego\\documents\\ondemna\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    886\u001b[0m         \u001b[1;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m         \u001b[1;31m# stateless function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 888\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    889\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    890\u001b[0m       \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\juan diego\\documents\\ondemna\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m-> 2943\u001b[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   2944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2945\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\juan diego\\documents\\ondemna\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1917\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1919\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\juan diego\\documents\\ondemna\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 560\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    561\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mc:\\users\\juan diego\\documents\\ondemna\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m:  ConcatOp : Dimensions of inputs should match: shape[0] = [1,64,64,48,64] vs. shape[1] = [1,64,64,49,64]\n\t [[node UNET-L4-F32/concatenate_14/concat (defined at <ipython-input-61-1f9e2dbe7e85>:2) ]] [Op:__inference_train_function_14285]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "model_3D.fit(train_data_generator_1, validation_data=holdout_data_generator,\n",
    "             epochs=num_epoch, callbacks=my_callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "spoken-gallery",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 182
    },
    "executionInfo": {
     "elapsed": 492,
     "status": "error",
     "timestamp": 1616314670342,
     "user": {
      "displayName": "Juan Diego Bermeo",
      "photoUrl": "",
      "userId": "11124578296137739363"
     },
     "user_tz": -60
    },
    "id": "sharing-plaintiff",
    "outputId": "64966d74-296a-479e-9124-b3b14ed9ac5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": " All dimensions except 4 must match. Input 1 has shape [1 32 32 21 128] and doesn't match input 0 with shape [1 32 32 20 128].\n\t [[node gradient_tape/UNET-L4-F32/concatenate_13/ConcatOffset (defined at <ipython-input-61-1f9e2dbe7e85>:2) ]] [Op:__inference_train_function_14285]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-62-63e3d828f0c8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m model_3D.fit(train_data_generator_2, validation_data=holdout_data_generator,\n\u001b[1;32m----> 2\u001b[1;33m              epochs=num_epoch, callbacks=my_callbacks)\n\u001b[0m",
      "\u001b[1;32mc:\\users\\juan diego\\documents\\ondemna\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1098\u001b[0m                 _r=1):\n\u001b[0;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1101\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\juan diego\\documents\\ondemna\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\juan diego\\documents\\ondemna\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    853\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 855\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    856\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\juan diego\\documents\\ondemna\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m-> 2943\u001b[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   2944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2945\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\juan diego\\documents\\ondemna\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1917\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1919\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\juan diego\\documents\\ondemna\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 560\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    561\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mc:\\users\\juan diego\\documents\\ondemna\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m:  All dimensions except 4 must match. Input 1 has shape [1 32 32 21 128] and doesn't match input 0 with shape [1 32 32 20 128].\n\t [[node gradient_tape/UNET-L4-F32/concatenate_13/ConcatOffset (defined at <ipython-input-61-1f9e2dbe7e85>:2) ]] [Op:__inference_train_function_14285]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "model_3D.fit(train_data_generator_2, validation_data=holdout_data_generator,\n",
    "             epochs=num_epoch, callbacks=my_callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "closed-robertson",
   "metadata": {
    "id": "promising-pride"
   },
   "outputs": [],
   "source": [
    "model_3D = unet3d(n_levels=4, initial_features=32, n_blocks=2, kernel_size=(3,3,2), pooling_size=2, strides=1,\n",
    "                image_height=128, image_width=128, image_depth=None, in_channels=1, out_channels=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "polish-expense",
   "metadata": {
    "id": "relative-baking"
   },
   "outputs": [],
   "source": [
    "model_3D.compile(\n",
    "    optimizer=Adam(learning_rate=0.001), \n",
    "    #optimizer=SGD(lr=0.01, momentum=0.99),\n",
    "    #loss='binary_crossentropy',\n",
    "    loss=dice_coef_loss,\n",
    "    metrics=[iou, iou_thresholded]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "marked-carnival",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 182
    },
    "executionInfo": {
     "elapsed": 492,
     "status": "error",
     "timestamp": 1616314670342,
     "user": {
      "displayName": "Juan Diego Bermeo",
      "photoUrl": "",
      "userId": "11124578296137739363"
     },
     "user_tz": -60
    },
    "id": "sharing-plaintiff",
    "outputId": "64966d74-296a-479e-9124-b3b14ed9ac5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": " ConcatOp : Dimensions of inputs should match: shape[0] = [1,64,64,48,64] vs. shape[1] = [1,64,64,49,64]\n\t [[node UNET-L4-F32/concatenate_17/concat (defined at <ipython-input-65-1f9e2dbe7e85>:2) ]] [Op:__inference_train_function_16750]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-65-1f9e2dbe7e85>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m model_3D.fit(train_data_generator_1, validation_data=holdout_data_generator,\n\u001b[1;32m----> 2\u001b[1;33m              epochs=num_epoch, callbacks=my_callbacks)\n\u001b[0m",
      "\u001b[1;32mc:\\users\\juan diego\\documents\\ondemna\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1098\u001b[0m                 _r=1):\n\u001b[0;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1101\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\juan diego\\documents\\ondemna\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\juan diego\\documents\\ondemna\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    886\u001b[0m         \u001b[1;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m         \u001b[1;31m# stateless function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 888\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    889\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    890\u001b[0m       \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\juan diego\\documents\\ondemna\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m-> 2943\u001b[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   2944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2945\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\juan diego\\documents\\ondemna\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1917\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1919\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\juan diego\\documents\\ondemna\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 560\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    561\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mc:\\users\\juan diego\\documents\\ondemna\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m:  ConcatOp : Dimensions of inputs should match: shape[0] = [1,64,64,48,64] vs. shape[1] = [1,64,64,49,64]\n\t [[node UNET-L4-F32/concatenate_17/concat (defined at <ipython-input-65-1f9e2dbe7e85>:2) ]] [Op:__inference_train_function_16750]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "model_3D.fit(train_data_generator_1, validation_data=holdout_data_generator,\n",
    "             epochs=num_epoch, callbacks=my_callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "sufficient-purple",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 182
    },
    "executionInfo": {
     "elapsed": 492,
     "status": "error",
     "timestamp": 1616314670342,
     "user": {
      "displayName": "Juan Diego Bermeo",
      "photoUrl": "",
      "userId": "11124578296137739363"
     },
     "user_tz": -60
    },
    "id": "sharing-plaintiff",
    "outputId": "64966d74-296a-479e-9124-b3b14ed9ac5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": " ConcatOp : Dimensions of inputs should match: shape[0] = [1,32,32,20,128] vs. shape[1] = [1,32,32,21,128]\n\t [[node UNET-L4-F32/concatenate_16/concat (defined at <ipython-input-65-1f9e2dbe7e85>:2) ]] [Op:__inference_train_function_16750]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-66-63e3d828f0c8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m model_3D.fit(train_data_generator_2, validation_data=holdout_data_generator,\n\u001b[1;32m----> 2\u001b[1;33m              epochs=num_epoch, callbacks=my_callbacks)\n\u001b[0m",
      "\u001b[1;32mc:\\users\\juan diego\\documents\\ondemna\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1098\u001b[0m                 _r=1):\n\u001b[0;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1101\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\juan diego\\documents\\ondemna\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\juan diego\\documents\\ondemna\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    853\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 855\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    856\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\juan diego\\documents\\ondemna\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m-> 2943\u001b[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   2944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2945\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\juan diego\\documents\\ondemna\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1917\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1919\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\juan diego\\documents\\ondemna\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 560\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    561\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mc:\\users\\juan diego\\documents\\ondemna\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m:  ConcatOp : Dimensions of inputs should match: shape[0] = [1,32,32,20,128] vs. shape[1] = [1,32,32,21,128]\n\t [[node UNET-L4-F32/concatenate_16/concat (defined at <ipython-input-65-1f9e2dbe7e85>:2) ]] [Op:__inference_train_function_16750]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "model_3D.fit(train_data_generator_2, validation_data=holdout_data_generator,\n",
    "             epochs=num_epoch, callbacks=my_callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "varying-vancouver",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.layers.Input(shape=(image_height, image_width, image_depth, in_channels))\n",
    "x = inputs\n",
    "    \n",
    "    convpars = dict(kernel_size=kernel_size, activation='relu', padding='same')\n",
    "    \n",
    "    #downstream\n",
    "    skips = {}\n",
    "    for level in range(n_levels):\n",
    "        for _ in range(n_blocks):\n",
    "            x = keras.layers.Conv3D(initial_features * 2 ** level, **convpars)(x)\n",
    "        if level < n_levels - 1:\n",
    "            skips[level] = x\n",
    "            x = keras.layers.MaxPool3D(pooling_size)(x)\n",
    "            \n",
    "    # upstream\n",
    "    for level in reversed(range(n_levels-1)):\n",
    "        x = keras.layers.Conv3DTranspose(initial_features * 2 ** level, strides=pooling_size, **convpars)(x)\n",
    "        x = keras.layers.Concatenate()([x, skips[level]])\n",
    "        for _ in range(n_blocks):\n",
    "            x = keras.layers.Conv3D(initial_features * 2 ** level, **convpars)(x)\n",
    "            \n",
    "    # output\n",
    "    activation = 'sigmoid' if out_channels == 1 else 'softmax'\n",
    "    x = keras.layers.Conv3D(out_channels, kernel_size=1, activation=activation, padding='same')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "regional-rider",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 128, 128, 98, 32)\n",
      "(1, 64, 64, 49, 1)\n"
     ]
    }
   ],
   "source": [
    "input_shape = (1, 128, 128, 98, 1)\n",
    "x = tf.random.normal(input_shape)\n",
    "y = tf.keras.layers.Conv3D(32, 3, activation='relu', padding='same')(x)\n",
    "y_pool = keras.layers.MaxPool3D(2)(x)\n",
    "print(y.shape)\n",
    "print(y_pool.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "guilty-overhead",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 165
    },
    "executionInfo": {
     "elapsed": 925,
     "status": "error",
     "timestamp": 1616314670783,
     "user": {
      "displayName": "Juan Diego Bermeo",
      "photoUrl": "",
      "userId": "11124578296137739363"
     },
     "user_tz": -60
    },
    "id": "1iVFJIjrQLDN",
    "outputId": "c42f7ca3-e3d3-46db-87f4-671083ccf72e"
   },
   "outputs": [],
   "source": [
    "model_3D.save(f'./{attepmt_name_dir}/end_of_training_version')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bored-closer",
   "metadata": {
    "id": "75F78xkXNw_0"
   },
   "source": [
    "Let's have it predict on the holdout data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blessed-proxy",
   "metadata": {
    "executionInfo": {
     "elapsed": 916,
     "status": "aborted",
     "timestamp": 1616314670776,
     "user": {
      "displayName": "Juan Diego Bermeo",
      "photoUrl": "",
      "userId": "11124578296137739363"
     },
     "user_tz": -60
    },
    "id": "H8UGKWjSgW8U"
   },
   "outputs": [],
   "source": [
    "iou_df = calculate_iou_holdout_set(holdout_df_=holdout_fold_0_df, img_dims=resize_dim,\n",
    "                                   model_=model, pixel_threshold=0.5,\n",
    "                                   prediction_batch_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baking-baker",
   "metadata": {
    "executionInfo": {
     "elapsed": 916,
     "status": "aborted",
     "timestamp": 1616314670778,
     "user": {
      "displayName": "Juan Diego Bermeo",
      "photoUrl": "",
      "userId": "11124578296137739363"
     },
     "user_tz": -60
    },
    "id": "VfllLbZoiWfW"
   },
   "outputs": [],
   "source": [
    "iou_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "human-poison",
   "metadata": {
    "executionInfo": {
     "elapsed": 911,
     "status": "aborted",
     "timestamp": 1616314670779,
     "user": {
      "displayName": "Juan Diego Bermeo",
      "photoUrl": "",
      "userId": "11124578296137739363"
     },
     "user_tz": -60
    },
    "id": "tKmnCsskk5_L"
   },
   "outputs": [],
   "source": [
    "iou_df.iou.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "anticipated-founder",
   "metadata": {},
   "outputs": [],
   "source": [
    "a= np.ones((2, 128, 128, 95))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "human-harmony",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def pad_along_axis(array: np.ndarray, target_length: int, axis: int = 0):\n",
    "        pad_size = target_length - array.shape[axis]\n",
    "\n",
    "        if pad_size <= 0:\n",
    "            return array\n",
    "\n",
    "        npad = [(0, 0)] * array.ndim\n",
    "        npad[axis] = (0, pad_size)\n",
    "\n",
    "        return np.pad(array, pad_width=npad, mode='constant', constant_values=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "renewable-manitoba",
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_along_axis(a, 96, axis=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grateful-stress",
   "metadata": {
    "id": "nC9FTpbIkgrn"
   },
   "source": [
    "# Check how a given trained model predicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loving-efficiency",
   "metadata": {
    "executionInfo": {
     "elapsed": 910,
     "status": "aborted",
     "timestamp": 1616314670780,
     "user": {
      "displayName": "Juan Diego Bermeo",
      "photoUrl": "",
      "userId": "11124578296137739363"
     },
     "user_tz": -60
    },
    "id": "Gfeb3yifk6cK"
   },
   "outputs": [],
   "source": [
    "cancer_pixels_df = pd.read_pickle('cancer_pixels_df')\n",
    "cancer_pixels_df.reset_index(inplace=True)\n",
    "cancer_pixels_df['index'] = cancer_pixels_df.image_name.map(lambda str_: str_.split('.nii.gz')[0].split('colon_')[1])\n",
    "\n",
    "tr_df_cancer_info = tr_df.join(\n",
    "    cancer_pixels_df.set_index(['index', 'depth_i'])[['cancer_pixel_area']],\n",
    "    how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elect-threat",
   "metadata": {
    "executionInfo": {
     "elapsed": 908,
     "status": "aborted",
     "timestamp": 1616314670780,
     "user": {
      "displayName": "Juan Diego Bermeo",
      "photoUrl": "",
      "userId": "11124578296137739363"
     },
     "user_tz": -60
    },
    "id": "j8MkJ9exlLDX"
   },
   "outputs": [],
   "source": [
    "img_with_cancer_gen = DataGenerator2D(df=tr_df_cancer_info[~(tr_df_cancer_info.cancer_pixel_area.isna())].sample(20),\n",
    "                                      x_col='x_tr_img_path', y_col='y_tr_img_path', batch_size=4, num_classes=None, shuffle=False, resize_dim=resize_dim)\n",
    "\n",
    "img_without_cancer_gen = DataGenerator2D(df=tr_df_cancer_info[tr_df_cancer_info.cancer_pixel_area.isna()].sample(20),\n",
    "                                     x_col='x_tr_img_path', y_col='y_tr_img_path', batch_size=4, num_classes=None, shuffle=False, resize_dim=resize_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worse-imperial",
   "metadata": {
    "executionInfo": {
     "elapsed": 906,
     "status": "aborted",
     "timestamp": 1616314670780,
     "user": {
      "displayName": "Juan Diego Bermeo",
      "photoUrl": "",
      "userId": "11124578296137739363"
     },
     "user_tz": -60
    },
    "id": "DzPA6CI0QFjl"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\n",
    "    f'./{attepmt_name_dir}/model_sampling.01-2.20.h5',\n",
    "    custom_objects={'iou':iou, 'iou_thresholded': iou_thresholded,\n",
    "                    'jaccard_distance_loss': jaccard_distance_loss,\n",
    "                    'binary_focal_loss_fixed': binary_focal_loss(gamma=2., alpha=0.7)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "documentary-blind",
   "metadata": {
    "executionInfo": {
     "elapsed": 905,
     "status": "aborted",
     "timestamp": 1616314670781,
     "user": {
      "displayName": "Juan Diego Bermeo",
      "photoUrl": "",
      "userId": "11124578296137739363"
     },
     "user_tz": -60
    },
    "id": "GV8k-1HcklkA"
   },
   "outputs": [],
   "source": [
    "#model = tf.keras.models.load_model('./5_epochs_v2', custom_objects={'iou':iou, 'iou_thresholded': iou_thresholded})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "radio-tunnel",
   "metadata": {
    "executionInfo": {
     "elapsed": 892,
     "status": "aborted",
     "timestamp": 1616314670782,
     "user": {
      "displayName": "Juan Diego Bermeo",
      "photoUrl": "",
      "userId": "11124578296137739363"
     },
     "user_tz": -60
    },
    "id": "YzTImj2fkztg"
   },
   "outputs": [],
   "source": [
    "# Let's see how it predicts for images of cancer\n",
    "for i, (X, y) in enumerate((img_with_cancer_gen)):\n",
    "    print(f'X: {X.shape}')\n",
    "    print(f'y: {y.shape}')\n",
    "\n",
    "    y_pred = model.predict(X)\n",
    "    print(y_pred.shape)\n",
    "    \n",
    "    for i in range(X.shape[0]):\n",
    "        f, (ax1, ax2, ax3) = plt.subplots(1, 3, sharey=True)\n",
    "        f.set_size_inches(20,20)\n",
    "\n",
    "        ax1.imshow(X[i,:,:])\n",
    "        ax1.set_title('Input image')\n",
    "        \n",
    "        ax2.imshow(y[i,:,:])\n",
    "        ax2.set_title('Ground truth, target label')\n",
    "\n",
    "        ax3.imshow(np.squeeze(y_pred[i,:,:]))\n",
    "        ax3.set_title('Predicted by the model')\n",
    "        \n",
    "        plt.show()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statutory-yemen",
   "metadata": {
    "executionInfo": {
     "elapsed": 881,
     "status": "aborted",
     "timestamp": 1616314670782,
     "user": {
      "displayName": "Juan Diego Bermeo",
      "photoUrl": "",
      "userId": "11124578296137739363"
     },
     "user_tz": -60
    },
    "id": "nzldbPX6m_y5"
   },
   "outputs": [],
   "source": [
    "# Let's see how it predicts for images of cancer\n",
    "for i, (X, y) in enumerate((img_without_cancer_gen)):\n",
    "    print(f'X: {X.shape}')\n",
    "    print(f'y: {y.shape}')\n",
    "\n",
    "    y_pred = model.predict(X)\n",
    "    print(y_pred.shape)\n",
    "    \n",
    "    for i in range(X.shape[0]):\n",
    "        f, (ax1, ax2, ax3) = plt.subplots(1, 3, sharey=True)\n",
    "        f.set_size_inches(20,20)\n",
    "\n",
    "        ax1.imshow(X[i,:,:])\n",
    "        ax1.set_title('Input image')\n",
    "        \n",
    "        ax2.imshow(y[i,:,:])\n",
    "        ax2.set_title('Ground truth, target label')\n",
    "\n",
    "        ax3.imshow(np.squeeze(y_pred[i,:,:]))\n",
    "        ax3.set_title('Predicted by the model')\n",
    "        \n",
    "        plt.show()\n",
    "        plt.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advised-patient",
   "metadata": {
    "id": "TUBcyakR3c3q"
   },
   "source": [
    "# Unet 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "minimal-plaza",
   "metadata": {
    "executionInfo": {
     "elapsed": 881,
     "status": "aborted",
     "timestamp": 1616314670783,
     "user": {
      "displayName": "Juan Diego Bermeo",
      "photoUrl": "",
      "userId": "11124578296137739363"
     },
     "user_tz": -60
    },
    "id": "wpK5ZL2v3f9A"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sympy\n",
      "  Downloading sympy-1.7.1-py3-none-any.whl (5.9 MB)\n",
      "Collecting mpmath>=0.19\n",
      "  Downloading mpmath-1.2.1-py3-none-any.whl (532 kB)\n",
      "Installing collected packages: mpmath, sympy\n",
      "Successfully installed mpmath-1.2.1 sympy-1.7.1\n"
     ]
    }
   ],
   "source": [
    "!pip install sympy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "chubby-polish",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sympy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "convenient-assist",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: 1, 7: 2}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sympy.ntheory.factorint(98)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "peripheral-automation",
   "metadata": {},
   "outputs": [],
   "source": [
    "biggest_3d_depth = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "inappropriate-wallpaper",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "90-32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "biological-professor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "58-32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "classical-marathon",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_cut(img_depth, biggest_3d_depth):\n",
    "    diff = img_depth - biggest_3d_depth\n",
    "    \n",
    "    if biggest_3d_depth == 2 or img_depth == 1:\n",
    "        return 0\n",
    "    \n",
    "    elif diff > 0:\n",
    "        print(biggest_3d_depth)\n",
    "        print(f'diff: {diff}')\n",
    "        return extract_cut(diff, biggest_3d_depth)\n",
    "    elif diff == 0 and biggest_3d_depth != 2:\n",
    "        print(biggest_3d_depth)\n",
    "        return 0\n",
    "    \n",
    "    elif diff < 0:\n",
    "        print(f'img_depth: {img_depth}')\n",
    "        print(f'biggest_3d_depth/2: {biggest_3d_depth/2}')\n",
    "        return extract_cut(img_depth, biggest_3d_depth/2) \n",
    "    \n",
    "    else: \n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "rising-disposition",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "diff: 69\n",
      "32\n",
      "diff: 37\n",
      "32\n",
      "diff: 5\n",
      "img_depth: 5\n",
      "biggest_3d_depth/2: 16.0\n",
      "img_depth: 5\n",
      "biggest_3d_depth/2: 8.0\n",
      "img_depth: 5\n",
      "biggest_3d_depth/2: 4.0\n",
      "4.0\n",
      "diff: 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_cut(img_depth=101, biggest_3d_depth=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "editorial-annotation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "32 *2 + 16 + 8 + 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "wooden-walnut",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "32*2 + 16 + 8 + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amino-belle",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_depth_cuts(img_depth, biggest_3d_depth):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "passive-belarus",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49.0"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "98/2"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "minimum example 3D.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
