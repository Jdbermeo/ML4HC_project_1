{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "advisory-summary",
   "metadata": {},
   "source": [
    "## Test IoU script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "lesser-agenda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from typing import Tuple\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "\n",
    "from model_utils import calculate_iou_holdout_set, calculate_iou\n",
    "from img_generator import build_train_test_df, DataGenerator2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "naughty-navigation",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path_source_dir = os.path.join('ml4h_proj1_colon_cancer_ct', 'ml4h_proj1_colon_cancer_ct')\n",
    "\n",
    "train_images_dir = os.path.join(data_path_source_dir, 'imagesTr')\n",
    "\n",
    "train_images_label_dir = os.path.join(data_path_source_dir, 'labelsTr')\n",
    "\n",
    "train_images_path_list = [os.path.join(train_images_dir, filename) for filename in os.listdir(train_images_dir) if filename != '.DS_Store' and '._' not in filename]\n",
    "train_images_labels_path_list = [os.path.join(train_images_label_dir, filename) for filename in os.listdir(train_images_label_dir) if filename != '.DS_Store' and '._' not in filename]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "overall-reporter",
   "metadata": {},
   "source": [
    "### Let's check if the IoU base function works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fossil-relation",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\juan diego\\documents\\ondemna\\venv\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: get_data() is deprecated in favor of get_fdata(), which has a more predictable return type. To obtain get_data() behavior going forward, use numpy.asanyarray(img.dataobj).\n",
      "\n",
      "* deprecated from version: 3.0\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 5.0\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "a = nib.load(train_images_labels_path_list[0]).get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "answering-airplane",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 512, 60)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "sufficient-command",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9988795518207283"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_iou(target=a, prediction=cv.GaussianBlur(a, (5,5), 0) > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "spread-warning",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_iou(target=a, prediction=cv.flip(a, 0) > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "alien-leonard",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_iou(target=a, prediction=cv.flip(cv.flip(a, 0), 0) > 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "consecutive-cassette",
   "metadata": {},
   "source": [
    "### Let's check if the function that uses the models prediction works well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "suited-witch",
   "metadata": {},
   "outputs": [],
   "source": [
    "from img_generator import build_train_test_df, DataGenerator2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "threatened-arthur",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path_source_dir = os.path.join('ml4h_proj1_colon_cancer_ct', 'ml4h_proj1_colon_cancer_ct')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disciplinary-spanking",
   "metadata": {},
   "source": [
    "# Let's check the behavior of the augmentation operations of the generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "united-benchmark",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(123)\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "improved-disco",
   "metadata": {},
   "source": [
    "Let's choose a set of images that have cancer labeled in them "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ecological-recording",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_df, x_ts_df = build_train_test_df(data_path_source_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "hearing-award",
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_pixels_df = pd.read_pickle('cancer_pixels_df')\n",
    "cancer_pixels_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "sitting-january",
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_pixels_df['index'] = cancer_pixels_df.image_name.map(lambda str_: str_.split('.nii.gz')[0].split('colon_')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "finite-rubber",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_df_only_cancer = cancer_pixels_df.set_index(['index', 'depth_i'])[['cancer_pixel_area']].join(tr_df, how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fresh-senator",
   "metadata": {},
   "source": [
    "### Identity case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "complex-training",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_iou_holdout_set(holdout_df_: pd.DataFrame, img_dims: Tuple, model_,\n",
    "                              pixel_threshold: float = 0.5, prediction_batch_size: int = 32) -> pd.DataFrame:\n",
    "    iou_list = list()\n",
    "\n",
    "    for img_dx, df_ in holdout_df_.groupby(level=0):\n",
    "        img_i_generator = DataGenerator2D(df=df_, x_col='x_tr_img_path', y_col='y_tr_img_path',\n",
    "                                          batch_size=prediction_batch_size, num_classes=None, shuffle=False,\n",
    "                                          resize_dim=img_dims)\n",
    "\n",
    "        # Predict for a group of cuts of the same image\n",
    "        for i, (X_cut_i, y_cut_i) in enumerate(img_i_generator):\n",
    "            #y_cut_i_predict = model_.predict(X_cut_i)\n",
    "            y_cut_i_predict = y_cut_i\n",
    "            \n",
    "            if len(y_cut_i_predict.shape) > 3:\n",
    "                y_cut_i_predict = np.squeeze(y_cut_i_predict, axis=3)\n",
    "\n",
    "            if i == 0:\n",
    "                y_i_predict_3d = y_cut_i_predict\n",
    "                y_i_3d = y_cut_i\n",
    "\n",
    "            else:\n",
    "                y_i_predict_3d = np.concatenate([y_i_predict_3d, y_cut_i_predict], axis=0)\n",
    "                y_i_3d = np.concatenate([y_i_3d, y_cut_i], axis=0)\n",
    "\n",
    "        # Measure IoU over entire 3D image after concatenating all of the cuts\n",
    "        iou_list.append({'index': img_dx,\n",
    "                         'iou': calculate_iou(target=y_i_3d, prediction=y_i_predict_3d > pixel_threshold)})\n",
    "\n",
    "        if (y_i_predict_3d > 0).any():\n",
    "            print(f'Predicted cancer for at least one pixel in image {img_dx}')\n",
    "\n",
    "    # Let's convert the iou to a pandas dataframe\n",
    "    iou_df = pd.DataFrame(iou_list).set_index('index')\n",
    "\n",
    "    return iou_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greek-antigua",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted cancer for at least one pixel in image 001\n",
      "Predicted cancer for at least one pixel in image 005\n",
      "Predicted cancer for at least one pixel in image 006\n",
      "Predicted cancer for at least one pixel in image 007\n",
      "Predicted cancer for at least one pixel in image 008\n",
      "Predicted cancer for at least one pixel in image 009\n",
      "Predicted cancer for at least one pixel in image 011\n",
      "Predicted cancer for at least one pixel in image 012\n",
      "Predicted cancer for at least one pixel in image 015\n",
      "Predicted cancer for at least one pixel in image 022\n",
      "Predicted cancer for at least one pixel in image 024\n",
      "Predicted cancer for at least one pixel in image 025\n",
      "Predicted cancer for at least one pixel in image 026\n",
      "Predicted cancer for at least one pixel in image 027\n",
      "Predicted cancer for at least one pixel in image 028\n",
      "Predicted cancer for at least one pixel in image 029\n",
      "Predicted cancer for at least one pixel in image 030\n",
      "Predicted cancer for at least one pixel in image 031\n",
      "Predicted cancer for at least one pixel in image 032\n",
      "Predicted cancer for at least one pixel in image 033\n",
      "Predicted cancer for at least one pixel in image 036\n",
      "Predicted cancer for at least one pixel in image 038\n",
      "Predicted cancer for at least one pixel in image 039\n",
      "Predicted cancer for at least one pixel in image 040\n",
      "Predicted cancer for at least one pixel in image 041\n",
      "Predicted cancer for at least one pixel in image 042\n",
      "Predicted cancer for at least one pixel in image 045\n",
      "Predicted cancer for at least one pixel in image 046\n",
      "Predicted cancer for at least one pixel in image 050\n",
      "Predicted cancer for at least one pixel in image 051\n",
      "Predicted cancer for at least one pixel in image 053\n",
      "Predicted cancer for at least one pixel in image 054\n",
      "Predicted cancer for at least one pixel in image 059\n",
      "Predicted cancer for at least one pixel in image 061\n",
      "Predicted cancer for at least one pixel in image 064\n",
      "Predicted cancer for at least one pixel in image 065\n",
      "Predicted cancer for at least one pixel in image 066\n",
      "Predicted cancer for at least one pixel in image 069\n",
      "Predicted cancer for at least one pixel in image 072\n",
      "Predicted cancer for at least one pixel in image 074\n",
      "Predicted cancer for at least one pixel in image 075\n",
      "Predicted cancer for at least one pixel in image 077\n",
      "Predicted cancer for at least one pixel in image 078\n",
      "Predicted cancer for at least one pixel in image 081\n",
      "Predicted cancer for at least one pixel in image 086\n",
      "Predicted cancer for at least one pixel in image 088\n",
      "Predicted cancer for at least one pixel in image 089\n",
      "Predicted cancer for at least one pixel in image 091\n",
      "Predicted cancer for at least one pixel in image 092\n",
      "Predicted cancer for at least one pixel in image 095\n",
      "Predicted cancer for at least one pixel in image 096\n",
      "Predicted cancer for at least one pixel in image 098\n",
      "Predicted cancer for at least one pixel in image 099\n",
      "Predicted cancer for at least one pixel in image 100\n",
      "Predicted cancer for at least one pixel in image 102\n",
      "Predicted cancer for at least one pixel in image 103\n",
      "Predicted cancer for at least one pixel in image 104\n",
      "Predicted cancer for at least one pixel in image 106\n",
      "Predicted cancer for at least one pixel in image 107\n",
      "Predicted cancer for at least one pixel in image 108\n",
      "Predicted cancer for at least one pixel in image 111\n"
     ]
    }
   ],
   "source": [
    "iou_df = calculate_iou_holdout_set(holdout_df_=tr_df, img_dims=(512, 512), model_=None,\n",
    "                              pixel_threshold= 0.5, prediction_batch_size= 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "foster-confidentiality",
   "metadata": {},
   "outputs": [],
   "source": [
    "iou_df.iou.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acoustic-myanmar",
   "metadata": {},
   "outputs": [],
   "source": [
    "iou_df.iou.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bright-karma",
   "metadata": {},
   "outputs": [],
   "source": [
    "iou_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "touched-launch",
   "metadata": {},
   "source": [
    "### Use Gaussian blur to reduce concordancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "respected-reasoning",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_iou_holdout_set(holdout_df_: pd.DataFrame, img_dims: Tuple, model_,\n",
    "                              pixel_threshold: float = 0.5, prediction_batch_size: int = 32) -> pd.DataFrame:\n",
    "    iou_list = list()\n",
    "\n",
    "    for img_dx, df_ in holdout_df_.groupby(level=0):\n",
    "        img_i_generator = DataGenerator2D(df=df_, x_col='x_tr_img_path', y_col='y_tr_img_path',\n",
    "                                          batch_size=prediction_batch_size, num_classes=None, shuffle=False,\n",
    "                                          resize_dim=img_dims)\n",
    "\n",
    "        # Predict for a group of cuts of the same image\n",
    "        for i, (X_cut_i, y_cut_i) in enumerate(img_i_generator):\n",
    "            #y_cut_i_predict = model_.predict(X_cut_i)\n",
    "            y_cut_i_predict = cv.GaussianBlur(y_cut_i, (11,11), 0)\n",
    "            \n",
    "            if len(y_cut_i_predict.shape) > 3:\n",
    "                y_cut_i_predict = np.squeeze(y_cut_i_predict, axis=3)\n",
    "\n",
    "            if i == 0:\n",
    "                y_i_predict_3d = y_cut_i_predict\n",
    "                y_i_3d = y_cut_i\n",
    "\n",
    "            else:\n",
    "                y_i_predict_3d = np.concatenate([y_i_predict_3d, y_cut_i_predict], axis=0)\n",
    "                y_i_3d = np.concatenate([y_i_3d, y_cut_i], axis=0)\n",
    "\n",
    "        # Measure IoU over entire 3D image after concatenating all of the cuts\n",
    "        iou_list.append({'index': img_dx,\n",
    "                         'iou': calculate_iou(target=y_i_3d, prediction=y_i_predict_3d > pixel_threshold)})\n",
    "\n",
    "    # Let's convert the iou to a pandas dataframe\n",
    "    iou_df = pd.DataFrame(iou_list).set_index('index')\n",
    "\n",
    "    return iou_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "circular-taylor",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted cancer for at least one pixel in image 001\n",
      "Predicted cancer for at least one pixel in image 005\n",
      "Predicted cancer for at least one pixel in image 006\n",
      "Predicted cancer for at least one pixel in image 007\n",
      "Predicted cancer for at least one pixel in image 008\n",
      "Predicted cancer for at least one pixel in image 009\n",
      "Predicted cancer for at least one pixel in image 011\n",
      "Predicted cancer for at least one pixel in image 012\n",
      "Predicted cancer for at least one pixel in image 015\n",
      "Predicted cancer for at least one pixel in image 022\n",
      "Predicted cancer for at least one pixel in image 024\n",
      "Predicted cancer for at least one pixel in image 025\n",
      "Predicted cancer for at least one pixel in image 026\n",
      "Predicted cancer for at least one pixel in image 027\n",
      "Predicted cancer for at least one pixel in image 028\n",
      "Predicted cancer for at least one pixel in image 029\n",
      "Predicted cancer for at least one pixel in image 030\n",
      "Predicted cancer for at least one pixel in image 031\n",
      "Predicted cancer for at least one pixel in image 032\n",
      "Predicted cancer for at least one pixel in image 033\n",
      "Predicted cancer for at least one pixel in image 036\n",
      "Predicted cancer for at least one pixel in image 038\n",
      "Predicted cancer for at least one pixel in image 039\n",
      "Predicted cancer for at least one pixel in image 040\n",
      "Predicted cancer for at least one pixel in image 041\n",
      "Predicted cancer for at least one pixel in image 042\n",
      "Predicted cancer for at least one pixel in image 045\n",
      "Predicted cancer for at least one pixel in image 046\n",
      "Predicted cancer for at least one pixel in image 050\n",
      "Predicted cancer for at least one pixel in image 051\n",
      "Predicted cancer for at least one pixel in image 053\n",
      "Predicted cancer for at least one pixel in image 054\n",
      "Predicted cancer for at least one pixel in image 059\n",
      "Predicted cancer for at least one pixel in image 061\n",
      "Predicted cancer for at least one pixel in image 064\n",
      "Predicted cancer for at least one pixel in image 065\n",
      "Predicted cancer for at least one pixel in image 066\n",
      "Predicted cancer for at least one pixel in image 069\n",
      "Predicted cancer for at least one pixel in image 072\n",
      "Predicted cancer for at least one pixel in image 074\n",
      "Predicted cancer for at least one pixel in image 075\n",
      "Predicted cancer for at least one pixel in image 077\n",
      "Predicted cancer for at least one pixel in image 078\n",
      "Predicted cancer for at least one pixel in image 081\n",
      "Predicted cancer for at least one pixel in image 086\n",
      "Predicted cancer for at least one pixel in image 088\n",
      "Predicted cancer for at least one pixel in image 089\n",
      "Predicted cancer for at least one pixel in image 091\n",
      "Predicted cancer for at least one pixel in image 092\n",
      "Predicted cancer for at least one pixel in image 095\n",
      "Predicted cancer for at least one pixel in image 096\n",
      "Predicted cancer for at least one pixel in image 098\n",
      "Predicted cancer for at least one pixel in image 099\n",
      "Predicted cancer for at least one pixel in image 100\n",
      "Predicted cancer for at least one pixel in image 102\n",
      "Predicted cancer for at least one pixel in image 103\n",
      "Predicted cancer for at least one pixel in image 104\n",
      "Predicted cancer for at least one pixel in image 106\n",
      "Predicted cancer for at least one pixel in image 107\n",
      "Predicted cancer for at least one pixel in image 108\n",
      "Predicted cancer for at least one pixel in image 111\n",
      "Predicted cancer for at least one pixel in image 112\n",
      "Predicted cancer for at least one pixel in image 114\n",
      "Predicted cancer for at least one pixel in image 115\n",
      "Predicted cancer for at least one pixel in image 117\n",
      "Predicted cancer for at least one pixel in image 118\n",
      "Predicted cancer for at least one pixel in image 119\n",
      "Predicted cancer for at least one pixel in image 120\n",
      "Predicted cancer for at least one pixel in image 122\n",
      "Predicted cancer for at least one pixel in image 124\n",
      "Predicted cancer for at least one pixel in image 126\n",
      "Predicted cancer for at least one pixel in image 127\n",
      "Predicted cancer for at least one pixel in image 129\n",
      "Predicted cancer for at least one pixel in image 131\n",
      "Predicted cancer for at least one pixel in image 133\n",
      "Predicted cancer for at least one pixel in image 134\n",
      "Predicted cancer for at least one pixel in image 136\n",
      "Predicted cancer for at least one pixel in image 137\n",
      "Predicted cancer for at least one pixel in image 138\n",
      "Predicted cancer for at least one pixel in image 139\n",
      "Predicted cancer for at least one pixel in image 140\n",
      "Predicted cancer for at least one pixel in image 141\n",
      "Predicted cancer for at least one pixel in image 142\n",
      "Predicted cancer for at least one pixel in image 143\n",
      "Predicted cancer for at least one pixel in image 144\n",
      "Predicted cancer for at least one pixel in image 145\n",
      "Predicted cancer for at least one pixel in image 148\n",
      "Predicted cancer for at least one pixel in image 149\n",
      "Predicted cancer for at least one pixel in image 154\n",
      "Predicted cancer for at least one pixel in image 155\n",
      "Predicted cancer for at least one pixel in image 157\n",
      "Predicted cancer for at least one pixel in image 159\n",
      "Predicted cancer for at least one pixel in image 161\n",
      "Predicted cancer for at least one pixel in image 162\n",
      "Predicted cancer for at least one pixel in image 163\n",
      "Predicted cancer for at least one pixel in image 164\n",
      "Predicted cancer for at least one pixel in image 165\n",
      "Predicted cancer for at least one pixel in image 166\n",
      "Predicted cancer for at least one pixel in image 168\n",
      "Predicted cancer for at least one pixel in image 169\n"
     ]
    }
   ],
   "source": [
    "iou_df = calculate_iou_holdout_set(holdout_df_=tr_df, img_dims=(512, 512), model_=None,\n",
    "                              pixel_threshold= 0.5, prediction_batch_size= 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "classical-lingerie",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iou_df.iou.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "twenty-fitness",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5930992058319379"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iou_df.iou.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "arbitrary-elder",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iou</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>001</th>\n",
       "      <td>0.091980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>005</th>\n",
       "      <td>0.699205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>006</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>007</th>\n",
       "      <td>0.524362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>008</th>\n",
       "      <td>0.571458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>0.410490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>0.349081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>0.770992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.302119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>0.680782</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            iou\n",
       "index          \n",
       "001    0.091980\n",
       "005    0.699205\n",
       "006    0.000000\n",
       "007    0.524362\n",
       "008    0.571458\n",
       "...         ...\n",
       "164    0.410490\n",
       "165    0.349081\n",
       "166    0.770992\n",
       "168    0.302119\n",
       "169    0.680782\n",
       "\n",
       "[100 rows x 1 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iou_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "strong-average",
   "metadata": {},
   "source": [
    "### Use flipping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protected-selection",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_iou_holdout_set(holdout_df_: pd.DataFrame, img_dims: Tuple, model_,\n",
    "                              pixel_threshold: float = 0.5, prediction_batch_size: int = 32) -> pd.DataFrame:\n",
    "    iou_list = list()\n",
    "\n",
    "    for img_dx, df_ in holdout_df_.groupby(level=0):\n",
    "        img_i_generator = DataGenerator2D(df=df_, x_col='x_tr_img_path', y_col='y_tr_img_path',\n",
    "                                          batch_size=prediction_batch_size, num_classes=None, shuffle=False,\n",
    "                                          resize_dim=img_dims)\n",
    "\n",
    "        # Predict for a group of cuts of the same image\n",
    "        for i, (X_cut_i, y_cut_i) in enumerate(img_i_generator):\n",
    "            #y_cut_i_predict = model_.predict(X_cut_i)\n",
    "            y_cut_i_predict = cv.flip(y_cut_i, 0)\n",
    "            \n",
    "            if len(y_cut_i_predict.shape) > 3:\n",
    "                y_cut_i_predict = np.squeeze(y_cut_i_predict, axis=3)\n",
    "\n",
    "            if i == 0:\n",
    "                y_i_predict_3d = y_cut_i_predict\n",
    "                y_i_3d = y_cut_i\n",
    "\n",
    "            else:\n",
    "                y_i_predict_3d = np.concatenate([y_i_predict_3d, y_cut_i_predict], axis=0)\n",
    "                y_i_3d = np.concatenate([y_i_3d, y_cut_i], axis=0)\n",
    "\n",
    "        # Measure IoU over entire 3D image after concatenating all of the cuts\n",
    "        iou_list.append({'index': img_dx,\n",
    "                         'iou': calculate_iou(target=y_i_3d, prediction=y_i_predict_3d > pixel_threshold)})\n",
    "\n",
    "        if (y_i_predict_3d > 0).any():\n",
    "            print(f'Predicted cancer for at least one pixel in image {img_dx}')\n",
    "\n",
    "    # Let's convert the iou to a pandas dataframe\n",
    "    iou_df = pd.DataFrame(iou_list).set_index('index')\n",
    "\n",
    "    return iou_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beneficial-layout",
   "metadata": {},
   "outputs": [],
   "source": [
    "iou_df = calculate_iou_holdout_set(holdout_df_=tr_df, img_dims=(512, 512), model_=None,\n",
    "                              pixel_threshold= 0.5, prediction_batch_size= 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bibliographic-capture",
   "metadata": {},
   "outputs": [],
   "source": [
    "iou_df.iou.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reverse-california",
   "metadata": {},
   "outputs": [],
   "source": [
    "iou_df.iou.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "turned-elephant",
   "metadata": {},
   "outputs": [],
   "source": [
    "iou_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
